<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.9.6"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Instruction analysis framework: Instruction analysis framework</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Instruction analysis framework
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.6 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
var searchBox = new SearchBox("searchBox", "search/",'.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:d3d9a9a6595521f9666a5e94cc830dab83b65699&amp;dn=expat.txt MIT */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */
</script>
<div id="main-nav"></div>
</div><!-- top -->
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div><div class="header">
  <div class="headertitle"><div class="title">Instruction analysis framework </div></div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md_README"></a></p>
<h1><a class="anchor" id="autotoc_md1"></a>
Description [En]</h1>
<h2><a class="anchor" id="autotoc_md2"></a>
Problem</h2>
<p>Currently, the open source RISC-V Instruction Set Architecture (ISA) is actively developing and gaining popularity. In the RISC-V community, the issue of optimizing programs specifically for this architecture is acute. In order to plan software migration, compiler developers and specialists optimizing particular sections of machine code in a non-trivial way manually need to understand which packages and utilities in popular GNU/Linux distributions on various platforms use, for example, vector extensions or instructions for speeding up encryption. This knowledge would help them understand how the compiler can be improved and in which programs there are sections of machine code that should be optimized manually for the RISC-V architecture.</p>
<p>In this context, it is also necessary to understand how the various GNU/Linux distributions are ready to migrate to RISC-V, that is, how the machine code of their packages is optimized and able to perform tasks in an effective manner.</p>
<p>To achieve this, a statistical analysis of the machine code is essential, namely, an analysis of the use of different types of machine instructions in the program code. However, the described problems are far from the only cases when such an analysis would be useful. Another example is the situation when the compiler developer needs to find out how the generated machine code of programs has changed in general after changes in the compiler.</p>
<p>This repository provides a framework that will make it much easier to answer such questions. On the one hand, it allows one to automate the collection of data on the machine instruction usage on different GNU/Linux distributions and architectures, and on the other hand, it provides a wide range of tools for statistical analysis and visualization of this data.</p>
<h2><a class="anchor" id="autotoc_md3"></a>
Getting started</h2>
<p>To start using the capabilities of the framework, you need to</p><ol type="1">
<li>Make a fork of this repository.</li>
<li>Clone the fork.</li>
<li>Create and activate virtual environment. <div class="fragment"><div class="line">[InstructionAnalysisFramework]$ python -m venv venv</div>
<div class="line">[InstructionAnalysisFramework]$ source venv/bin/activate</div>
</div><!-- fragment --></li>
<li>Install requirements. <div class="fragment"><div class="line">(venv) [InstructionAnalysisFramework]$ pip install -r requirements.txt</div>
</div><!-- fragment --></li>
</ol>
<h2><a class="anchor" id="autotoc_md4"></a>
Data collection</h2>
<p>A <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/data_collection/data_collection.py">Python program</a> was written to collect the data. It provides many options for configuration for the needs of particular users. In general, the program runs through certain files in parallel and tries to get an assembly listing of each file. If the attempt is successful, that is, the file contains the code, the path to the file and the number of all instructions found in it are recorded in a csv table, which is the result of the program. Program parameters determine which files program goes through. One can get acquainted with them as follows: </p><div class="fragment"><div class="line">(venv) [...]$ python data_collection/data_collection.py --help</div>
</div><!-- fragment --><p> For example, one can run a program on all files that are available in the system as follows: </p><div class="fragment"><div class="line">(venv) [...]$ python data_collection/data_collection.py -r &lt;path to the table&gt;</div>
</div><!-- fragment --> <h3><a class="anchor" id="autotoc_md5"></a>
On different GNU/Linux distributions</h3>
<p>In order for data collection to take place on different GNU/Linux distributions, regardless of which operating system is installed on the machine on which the program is running, the program is run in Docker containers. The <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/tree/master/dockerfiles">dockerfiles</a> folder contains dockerfiles for building images. They include the installation of a utility for obtaining assembly listings of programs, as well as the installation of all programs whose machine code data the user wants to get. This approach allows the framework to achieve extensibility — to add a distribution for scanning, one just needs to add the corresponding docker file.</p>
<p>Data is collected using GitHub Actions in two stages (<a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/.github/workflows/DockerContainersDC.yml">yml-file</a>). First, the images are collected according to docker files and published in the <a href="https://hub.docker.com/repository/docker/danilapechenev/instruction-analysis/general">repository</a> on DockerHub. If the dockerfile has not been modified since the last GitHub Actions workflow, the image is not reassembled. At the next stage, data is collected on all distributions in parallel: in each distribution, an image is loaded from DockerHub, a Docker container is launched, and a program is run in it that generates a table with data. The resulting tables are stored in archives on GitHub Actions as workflow artifacts. </p>
<h3><a class="anchor" id="autotoc_md6"></a>
On different platforms</h3>
<p>The framework provides the ability to scan disk images (now in .iso format), which allows one to collect data from different instruction set architectures (ISA). One can run a <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/data_collection/local_disk_image_collection.sh">script</a> to collect data from a disk image that is already downloaded, or use a <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/data_collection/url_disk_image_collection.sh">script</a> to scan the image by its URL. For example, one can collect data from an image by URL as follows: </p><div class="fragment"><div class="line">(venv) [...]$ ./data_collection/url_iso_collection.sh &lt;link to disk image&gt; &lt;table path&gt;</div>
</div><!-- fragment --><p>In addition, data from disk images by their URL can be collected using GitHub Actions (<a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/.github/workflows/DiskImagesDC.yml">yml-file</a>). For this purpose, some information about the processed images is written to a special <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/disk-images.json">json file</a>, in particular, the URL and objdump, which will be used in the data collection process. Then, the process on GitHub Actions, using an auxiliary <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/data_collection/gha_disk_image_scanner.py">Python program</a>, reads data from a json file, installs the necessary utilities, downloads and scans disk images. The resulting tables are stored in archives on GitHub Actions as workflow artifacts.</p>
<h2><a class="anchor" id="autotoc_md7"></a>
Data analysis</h2>
<p>Archives with tables are downloaded and analyzed in the Jupiter Notebook interactive environment both using standard functions provided by the pandas library and using <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/data_analysis/analysis_tool.py">functions</a> provided by the framework. An example of such an analysis with a demonstration of some capabilities of the tool is presented in <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/data_analysis/demo.ipynb">demo.ipynb</a>. The functions for analysis and visualization are carefully documented. The documentation is <a href="https://danila-pechenev.github.io/InstructionAnalysisFramework/namespaceanalysis__tool.html">published</a> on GitHub Pages and is updated automatically when changes occur.</p>
<h2><a class="anchor" id="autotoc_md8"></a>
Dvision of instructions into categories and groups</h2>
<p>There are a lot of instructions, and this can create inconvenience when analyzing data about their use. Framework users may want to divide instructions into clusters. At the moment, the framework provides an approach for solving this problem for the x86-64 architecture. For this purpose, a <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/scripts/x86-64_instructions.py">Python program</a> was written that collects information from the <a href="https://linasm.sourceforge.net/docs/instructions/index.php">site</a>, covering a fairly large number of instructions. We call the category of the instruction the section of the site on the left where it is included, and the group — its subsection in it. Thus, the program collects for each instruction its description, category and group and stores the result in a <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/x86-64_instructions.json">json file</a>. The division of instructions into categories and groups significantly increases completeness of information and clarity of data analysis.</p>
<h1><a class="anchor" id="autotoc_md9"></a>
Описание [Ru]</h1>
<h2><a class="anchor" id="autotoc_md10"></a>
Проблема</h2>
<p>В настоящее время активно развивается и набирает популярность открытая процессорная архитектура RISC-V. В сообществе RISC-V остро стоит вопрос оптимизации программ именно под эту архитектуру. Для планирования миграции программного обеспечения разработчикам компиляторов и специалистам, оптимизирующим отдельные участки машинного кода нетривиальным образом вручную, необходимо понимать, какие пакеты и утилиты в популярных дистрибутивах GNU/Linux используют, например, векторные расширения или инструкции для ускорения шифрования. Эти знания помогли бы им понять, как можно улучшить комилятор и в каких программах есть участки кода, которые необходимо оптимизировать вручную для архитектуры RISC-V.</p>
<p>В этом контексте также необходимо понимать, как различные дистрибутивы GNU/Linux готовы для миграции на RISC-V, то есть, насколько оптимизирован машинный код их пакетов.</p>
<p>Для этого необходим статистический анализ использования различный инструкций в машинном коде программ. Однако описанные проблемы являются далеко не единственными случаями, когда был бы полезен такой анализ. Другим примером является ситуация, когда разработчику компилятора необходимо узнать, как в целом поменялся сгенерированный машинный код программ после изменений в компиляторе.</p>
<p>Этот репозиторий предоставляет фреймворк, который значительно упростит ответы на такого рода вопросы. С одной стороны, он позволяет автоматизировать сбор данных об использовании машинных инструкций на разных архитектурах и дистрибутивах GNU/Linux, а с другой &ndash; предоставляет широкий инструментарий для статистического анализа и визуализации этих данных.</p>
<h2><a class="anchor" id="autotoc_md11"></a>
Начало работы</h2>
<p>Чтобы начать пользоваться возможностями фреймворка, необходимо</p><ol type="1">
<li>Сделать форк этого репозитория.</li>
<li>Склонировать форк.</li>
<li>Создать и активировать виртуальное окружение. <div class="fragment"><div class="line">[InstructionAnalysisFramework]$ python -m venv venv</div>
<div class="line">[InstructionAnalysisFramework]$ source venv/bin/activate</div>
</div><!-- fragment --></li>
<li>Установить необходимые пакеты. <div class="fragment"><div class="line">(venv) [InstructionAnalysisFramework]$ pip install -r requirements.txt</div>
</div><!-- fragment --> </li>
</ol>
<h2><a class="anchor" id="autotoc_md12"></a>
Сбор данных</h2>
<p>Для сбора данных была написана <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/data_collection/data_collection.py">Python-программа</a>. Он предоставляет множество возможностей для конфигурации под нужды конкретных пользователей. В целом, программа параллельно проходит по определенным файлам и пробует получить ассемблерный листинг каждого файла. Если попытка удачна, то есть файл содержит код, путь до файла и количество всех инструкций, встречающихся в нем, записываются в csv-таблицу, которая и является результатом работы программы. По каким именно файлам необходимо пройтись и определяют параметры программы. Ознакомиться с ними можно так: </p><div class="fragment"><div class="line">(venv) [...]$ python data_collection/data_collection.py --help</div>
</div><!-- fragment --><p> Например, запустить программу на всех файлах, которые имеются в системе, можно следующим образом: </p><div class="fragment"><div class="line">(venv) [...]$ python data_collection/data_collection.py -r &lt;path to the table&gt;</div>
</div><!-- fragment --> <h3><a class="anchor" id="autotoc_md13"></a>
На разных дистрибутивах GNU/Linux</h3>
<p>Чтобы сбор данных мог происходить на разных дистрибутивах GNU/Linux вне зависимости от того, какая операционная система установлена на машине, производящей запуск, программа запускается в Docker-контейнерах. В папке <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/tree/master/dockerfiles">dockerfiles</a> находятся докерфайлы для сборки образов. Они включают в себя установку утилиты для получения ассемблерных листингов программ, а также установку всех программ, данные о машинном коде которых пользователь хочет получить. Такой подход позволяет достигнуть расширяемости — чтобы добавить дистрибутив для сканирования, нужно лишь добавить соответствующий ему докерфайл.</p>
<p>Сбор данных происходит при помощи GitHub Actions в два этапа (<a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/.github/workflows/DockerContainersDC.yml">yml-файл</a>). Сначала образы собираются согласно докерфайлам и публикуются в <a href="https://hub.docker.com/repository/docker/danilapechenev/instruction-analysis/general">репозитории</a> на DockerHub. В случае, если докерфайл не был изменен с момента последнего запуска процесса на GitHub Actions, повторная сборка образа не производится. На следующем этапе данные собираются на всех дистрибутивах параллельно: в каждом дистрибутиве загружается образ с DockerHub, запускается Docker-контейнер, а в нем запускается программа, генерирующая таблицу с данными. Полученные таблицы сохраняются в архивах как артефакты запуска процесса на GitHub Actions. </p>
<h3><a class="anchor" id="autotoc_md14"></a>
На разных платформах</h3>
<p>Фреймворк предоставляет возможность сканирования образов дисков, что позволяет собирать данные с разных процессорных архитектур. Можно запустить <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/data_collection/local_disk_image_collection.sh">скрипт</a> для сбора данных с уже скачанного образа диска или воспользовать <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/data_collection/url_disk_image_collection.sh">скриптом</a> для сканирования образа по его URL. Например, собрать данные с образа по URL можно так: </p><div class="fragment"><div class="line">(venv) [...]$ ./data_collection/url_iso_collection.sh &lt;link to disk image&gt; &lt;table path&gt;</div>
</div><!-- fragment --><p>Помимо этого, данные с образов дисков по их URL могут собираться при помощи GitHub Actions (<a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/.github/workflows/DiskImagesDC.yml">yml-файл</a>). Для этого в специальный <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/disk-images.json">json-файл</a> записывается некоторая информация об обрабатываемых образах, в частности, URL и objdump, который будет использоваться в процессе сбора данных. Далее процесс на GitHub Actions, используя вспомогательную <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/data_collection/gha_disk_image_scanner.py">Python-программу</a>, считывает данные с json-файла, устанавливает необходимые утилиты, скачивает и сканирует образы дисков. Полученные таблицы сохраняются в архивах как артефакты запуска процесса на GitHub Actions.</p>
<h2><a class="anchor" id="autotoc_md15"></a>
Анализ данных</h2>
<p>Архивы с таблицами скачиваются и анализируются в интерактивной среде Jupyter Notebook как при помощи стандартных функций, предоставляемых библиотекой pandas, так и с помощью <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/data_analysis/analysis_tool.py">функций</a>, предоставляемых фреймворком. Пример такого анализа с демонстрацией некоторых возможностей инструмента представлен в <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/data_analysis/demo.ipynb">demo.ipynb</a>. Функции для анализа и визуализации тщательно документирована. Документация <a href="https://danila-pechenev.github.io/InstructionAnalysisFramework/namespaceanalysis__tool.html">публикуется</a> на GitHub Pages и при изменениях обновляется автоматически.</p>
<h2><a class="anchor" id="autotoc_md16"></a>
Разделение инструкций на категории и группы</h2>
<p>Инструкций очень много, и это может создать неудобства при анализе данных об их использовании. У пользователей фреймворка может возникнуть желание разделить инструкции на кластеры. В настоящий момент, фреймворк предоставяет способ решения этой проблемы для архитектуры x86-64. Для этого была написана <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/scripts/x86-64_instructions.py">Python-программа</a>, собирающий информацию с <a href="https://linasm.sourceforge.net/docs/instructions/index.php">сайта</a>, где представлено достаточно большое количество инструкций. Мы будем называть категорией инструкции тот раздел сайта слева, куда она включена, а группой — ее подраздел в нем. Таким образом, программа собирает для каждой инструкции ее описание, категорию и группу и сохраняет результат в <a href="https://github.com/Danila-Pechenev/InstructionAnalysisFramework/blob/master/x86-64_instructions.json">json-файле</a>. Разделение инструкций на категории и группы значительно повышает информативность и ясность анализа данных. </p>
</div></div><!-- PageDoc -->
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.6
</small></address>
</body>
</html>
